{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c22e03e",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b74d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"C:/Users/ppirthip/OneDrive - Intel Corporation/Speckle/\"\n",
    "df = pd.read_csv(path+\"SNR_R5_ww51.4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b8d9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffa341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for rows will blank delta\n",
    "import numpy as np\n",
    "df1 = df[df[\"DELTA\"].isnull()]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a02ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make folder for dataprep if it doesn't exist\n",
    "import os\n",
    "dataprep_path = path + 'DataPreparation/' \n",
    "if not os.path.exists(dataprep_path):\n",
    "    os.makedirs(dataprep_path)\n",
    "    print(\"DataPreparation folder created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c85577",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(dataprep_path+\"Blank_delta.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3881c27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove blank delta\n",
    "import numpy as np\n",
    "df = df[df[\"DELTA\"].notnull()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddfc8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DELTA\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d005ea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column for target\n",
    "import numpy as np\n",
    "df[\"SPECKLE\"] = np.where(df[\"DELTA\"]==0,0,1)\n",
    "cols = df.columns.tolist()\n",
    "cols = [cols[-1]]+cols[:-1] #move speckle col to the front\n",
    "df = df.reindex(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aac2735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SPECKLE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1551639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c316f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_seq_items = 2000\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33308d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caec68fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a104d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(dataprep_path+\"SNR_R5_ww51.4_Blankdeltarem.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120005a2",
   "metadata": {},
   "source": [
    "### 1) Check for VID duplicates (Unique VID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754bdd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046599d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SPECKLE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc0ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates(df):\n",
    "    \"\"\"\n",
    "    Check for duplicates in VID \n",
    "    df[DataFrame]: input df    \n",
    "    \"\"\"\n",
    "    if df['VID'].duplicated().any():\n",
    "        print(\"There are duplicates in VID\")\n",
    "        df_dup = df[df.duplicated(subset=['VID'])] #get the duplicates in df, returns repeated rows only \n",
    "        df= df[df[\"VID\"].isin(df_dup[\"VID\"])] #get all the duplicates in df, returns original + repeated rows \n",
    "        return df\n",
    "    else:\n",
    "        print(\"There are no duplicates in VID\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276cf39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dup = check_duplicates(df)\n",
    "df_dup #78 rows of duplicates, 39 duplicated VIDs -> ONLY 1 VID has values, the rest all blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e39dd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dup.to_csv(dataprep_path+\"SNR_R5_ww51.4_DuplicateVID.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3bec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dup_withval = df.loc[df['VID'] == 'M1BH477200042']\n",
    "df_dup_withval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf69a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicates_handling(df,keep):\n",
    "    \"\"\"\n",
    "    Remove duplicates if there is any\n",
    "    df[DataFrame]: input df\n",
    "    keep: {‘first’, ‘last’, False}: Determines which duplicates (if any) to keep. \n",
    "    - first : Drop duplicates except for the first occurrence. \n",
    "    - last : Drop duplicates except for the last occurrence. \n",
    "    - False : Drop all duplicates.\n",
    "    \"\"\"\n",
    "    df = df.drop_duplicates(subset=['VID'],keep=keep) #remove duplicates from df\n",
    "#     display(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69581b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = duplicates_handling(df,keep=False)\n",
    "df = pd.concat([df, df_dup_withval], ignore_index=True)\n",
    "df = duplicates_handling(df,keep=\"first\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303083a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_duplicates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b145d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SPECKLE\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126afadc",
   "metadata": {},
   "source": [
    "### 2 ) NA handling (NA removal/imputation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a47e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check column for nulls\n",
    "def check_colna(df):\n",
    "    \"\"\"\n",
    "    Check each column for nulls. Returns Feature, total null and % of null for each column\n",
    "    df[DataFrame]: dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    colna_df = pd.DataFrame(columns =[\"Feature\", \"Total Null\", \"% of Null\"])\n",
    "    for col in df.columns: \n",
    "        #checking if there is any null in the column\n",
    "\n",
    "        if df[col].isnull().sum()>0: \n",
    "            \n",
    "            # if null present, total number of null in the column stores here\n",
    "            total_null = df[col].isnull().sum() \n",
    "            new_row = {'Feature':col, 'Total Null':total_null, '% of Null':total_null*100/len(df)}\n",
    "            #append row to the dataframe\n",
    "            colna_df = colna_df.append(new_row, ignore_index=True)\n",
    "            \n",
    "    colna_df= colna_df.sort_values(\"% of Null\", ascending=False)    \n",
    "    return colna_df  \n",
    "\n",
    "# check rows for nulls\n",
    "def check_rowna(df,supporting_fs):  \n",
    "    \"\"\"\n",
    "    Check each row for nulls.Returns VID, total null and % of null for each row\n",
    "    df[DataFrame]: dataframe\n",
    "    supporting_fs[list]: all features not used for ML except VID and SPECKLE(target)\n",
    "    \"\"\"\n",
    "    df = df.drop(supporting_fs,axis=1)    \n",
    "    colrow_df = pd.DataFrame(columns =[\"SPECKLE\",\"VID\", \"Total Null\", \"% of Null\"])\n",
    "    for i in df.index: \n",
    "        #checking if there is any null in the row\n",
    "        if df.iloc[i].isnull().sum()>0:             \n",
    "            # if null present, total number of null in the row stores here\n",
    "            total_null = df.iloc[i].isnull().sum() \n",
    "            new_row = {'SPECKLE':df.iloc[i,0],'VID':df.iloc[i,1], 'Total Null':total_null, '% of Null':round(total_null*100/(len(df.columns)-2),2)}\n",
    "            #append row to the dataframe\n",
    "            colrow_df = colrow_df.append(new_row, ignore_index=True)\n",
    "            \n",
    "    colrow_df= colrow_df.sort_values(\"% of Null\", ascending=False)    \n",
    "    return colrow_df   \n",
    "\n",
    "# Drop columns based on NA threshold limit\n",
    "def drop_NAcol(df,NA_limit):\n",
    "    '''\n",
    "    Drops columns based on proportion of NA in column\n",
    "    df[DataFrame]: df\n",
    "    NA_limit[float/int]: Columns with proportion of NA above NA_limit will be dropped\n",
    "    '''\n",
    "    threshold = len(df)*(1-NA_limit)\n",
    "    df=df.dropna(axis=1, thresh=threshold)\n",
    "    print(df.shape)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2ea696",
   "metadata": {},
   "source": [
    "#### a) Check column for nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd759176",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df[\"SPECKLE\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b38fa56",
   "metadata": {},
   "source": [
    "#### i) check nulls in whole column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc1645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check column na for whole df\n",
    "colna_df =check_colna(df)\n",
    "colna_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6bf91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check columns with 100% NA\n",
    "colna_df.loc[colna_df[\"% of Null\"] ==100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb32cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "colna_df.to_csv(dataprep_path+\"NA_Cols.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f868ffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns with all NA\n",
    "df = df.dropna(axis=1, how='all')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a43099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_colna(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfa48e0",
   "metadata": {},
   "source": [
    "#### ii) check nulls in column for speckle only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7953515",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d20e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check column na for speckle\n",
    "colna_speckle_df =check_colna(df.loc[df['SPECKLE'] == 1])\n",
    "colna_speckle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dd1c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(colna_speckle_df.loc[colna_speckle_df[\"% of Null\"] ==100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3158c68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "colna_speckle_df.to_csv(path+\"/DataPreparation/NA_Cols_speckle.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daa5a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "col100na_speckle_df = colna_speckle_df.loc[colna_speckle_df[\"% of Null\"] ==100]\n",
    "df = df.loc[:,~df.columns.isin(col100na_speckle_df['Feature'])]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2969c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "colna_speckle_df =check_colna(df.loc[df['SPECKLE'] == 1])\n",
    "colna_speckle_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312604b1",
   "metadata": {},
   "source": [
    "#### iii) check nulls in column for non-speckle only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b701231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check column na for non-speckle\n",
    "colna_nonspeckle_df =check_colna(df.loc[df['SPECKLE'] == 0])\n",
    "colna_nonspeckle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3979ffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check column na for whole df\n",
    "colna_df_no100NA =check_colna(df)\n",
    "colna_df_no100NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23102118",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a68d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "colna_df_no100NA.to_csv(path+\"/DataPreparation/NA_Cols_without100NA.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78239311",
   "metadata": {},
   "source": [
    "#### b) Drop columns based on threshold limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8ef2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_NAcol(df,0.8) #drop columns with >80% NA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e93c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1f815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_colna(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea73146",
   "metadata": {},
   "source": [
    "#### c) Check row for nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f0d4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df[\"SPECKLE\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c303654",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_seq_items = 2000\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671f9d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "supporting_fs = ['ULT@MIDAS_6261_U1', 'SORTLOT', 'SORTLOT7', 'WAFER',\n",
    "       'XLOC', 'YLOC', 'ULT@MIDAS_6261_U2', 'IB@6261[CLASSHOT]',\n",
    "       'FB@6261[CLASSHOT]', 'TEST RESULTS', 'TEST RESULTS BITS', 'TR_BITS',\n",
    "       'INCOMING', 'INCOMING BITS', 'INC_BITS', 'OUTGOING', 'OUTGOING BITS',\n",
    "       'OUT_BITS', 'DELTA']\n",
    "rowna_df = check_rowna(df,supporting_fs)\n",
    "rowna_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a1e071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rows with 100% NA\n",
    "row100na_df = rowna_df.loc[rowna_df[\"% of Null\"] ==100.00]\n",
    "row100na_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1720695",
   "metadata": {},
   "outputs": [],
   "source": [
    "row100na_df.to_csv(dataprep_path+\"NA_Rows.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d66758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "row100na_df[\"SPECKLE\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7c6e97",
   "metadata": {},
   "source": [
    "#### d) Row NA handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1559aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows with 100% NA\n",
    "df = df[~df[\"VID\"].isin(row100na_df[\"VID\"])]\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac37424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SPECKLE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6264c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb98ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check row na\n",
    "supporting_fs = ['ULT@MIDAS_6261_U1', 'SORTLOT', 'SORTLOT7', 'WAFER',\n",
    "       'XLOC', 'YLOC', 'ULT@MIDAS_6261_U2', 'IB@6261[CLASSHOT]',\n",
    "       'FB@6261[CLASSHOT]', 'TEST RESULTS', 'TEST RESULTS BITS', 'TR_BITS',\n",
    "       'INCOMING', 'INCOMING BITS', 'INC_BITS', 'OUTGOING', 'OUTGOING BITS',\n",
    "       'OUT_BITS', 'DELTA']\n",
    "check_rowna(df,supporting_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aa3830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(['PTH_POWER::POWER_X_SCREEN_E_BEGIN_X_X_X_X_CALC_PP_CDYN_INDICATOR_CDYN_DATA@132110'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48396637",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ead650",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NA imputation\n",
    "def NA_impute(df,imptype):\n",
    "    \"\"\"\n",
    "    Impute NA\n",
    "    df[DataFrame]:df\n",
    "    imptype[string]: \"mean\" to impute data with mean, \"median\" to impute data with median\n",
    "    \"\"\"\n",
    "    if imptype == \"mean\":        \n",
    "        df = df.fillna(df.mean())\n",
    "    if imptype == \"median\":\n",
    "        df = df.fillna(df.median())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d2cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = NA_impute(df,imptype=\"median\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873f878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_rowna(df,supporting_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e49fa0",
   "metadata": {},
   "source": [
    "### 3) Handling of negative values (Imputation/conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eab1541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create a dataframe with supporting features columns (to account for string variables)\n",
    "supporting_fs_df = df[[\"ULT@MIDAS_6261_U1\", \"SORTLOT\", \"SORTLOT7\", \"WAFER\",\n",
    "        \"XLOC\", \"YLOC\", \"ULT@MIDAS_6261_U2\", \"IB@6261[CLASSHOT]\",\n",
    "        \"FB@6261[CLASSHOT]\",\"TEST RESULTS\", \"TEST RESULTS BITS\", \"TR_BITS\", \"INCOMING\",\n",
    "        \"INCOMING BITS\", \"INC_BITS\", \"OUTGOING\", \"OUTGOING BITS\", \"OUT_BITS\",\"DELTA\",\"VID\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6428ec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "supporting_fs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525a51a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create a dataframe df_keep with IDV and HVQK token family columns\n",
    "cols_to_keep=[\"IDV\", \"HVQK\"]\n",
    "IDV_HVQK_df = df[df.columns[df.columns.str.startswith(tuple(cols_to_keep))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4afd78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDV_HVQK_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee8a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create dataset with supporting features, IDV and HVQK token family columns\n",
    "#Concatenating supporting_fs_df and IDV_HVQK_df along columns\n",
    "df_keep = pd.concat([supporting_fs_df, IDV_HVQK_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a5fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8bea3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create dataframe - drop columns with IDV token family columns\n",
    "df_to_convert = df.drop([col for col in df if col.startswith('IDV')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb1c41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create dataframe - drop columns with HVQK token family columns\n",
    "df_to_convert = df_to_convert.drop([col for col in df if col.startswith('HVQK')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1170fc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create dataframe - drop columns with supporting features columns\n",
    "df_to_convert = df_to_convert.drop([\"ULT@MIDAS_6261_U1\", \"SORTLOT\", \"SORTLOT7\", \"WAFER\",\n",
    "        \"XLOC\", \"YLOC\", \"ULT@MIDAS_6261_U2\", \"IB@6261[CLASSHOT]\",\n",
    "        \"FB@6261[CLASSHOT]\",\"TEST RESULTS\", \"TEST RESULTS BITS\", \"TR_BITS\", \"INCOMING\",\n",
    "        \"INCOMING BITS\", \"INC_BITS\", \"OUTGOING\", \"OUTGOING BITS\", \"OUT_BITS\",\"DELTA\",\"VID\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82c2635",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_convert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457b7c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert negative columns with specific token family prefix\n",
    "df_positive = df_to_convert.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f92483",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b541cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create dataset with some parameters converted to absolute values\n",
    "#Concatenating df_keep and df_positive along columns\n",
    "df = pd.concat([df_keep, df_positive], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6370fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339af53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking column for -5555 values\n",
    "def check_col_negative5555(df):\n",
    "    \"\"\"\n",
    "    Check each column for -5555 values. Returns Feature, total -5555 values and % of -5555 values for each column\n",
    "    df[DataFrame]: dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    col_negative5555_df = pd.DataFrame(columns =[\"Feature\", \"Total -5555 Values\", \"% of -5555 Values\"])\n",
    "    for col in df.columns: \n",
    "        #checking if there is any -5555 in the column\n",
    "\n",
    "        if df[col].isin([-5555]).sum()>0: \n",
    "            \n",
    "            # if -5555 value present, total number of -5555 value in the column stores here\n",
    "            total_negative_5555 = df[col].isin([-5555]).sum() \n",
    "            new_row = {'Feature':col, 'Total -5555 Values':total_negative_5555, '% of -5555 Values':round(total_negative_5555*100/len(df),2)}\n",
    "            #append row to the dataframe\n",
    "            col_negative5555_df = col_negative5555_df.append(new_row, ignore_index=True)\n",
    "            \n",
    "    col_negative5555_df = col_negative5555_df.sort_values(\"% of -5555 Values\", ascending=False)    \n",
    "    return col_negative5555_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4682fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check column na for whole df\n",
    "col_negative5555_df =check_col_negative5555(df)\n",
    "col_negative5555_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716f5d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking column for -999 values\n",
    "def check_col_negative999(df):\n",
    "    \"\"\"\n",
    "    Check each column for -999 values. Returns Feature, total -999 values and % of -999 values for each column\n",
    "    df[DataFrame]: dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    col_negative999_df = pd.DataFrame(columns =[\"Feature\", \"Total -999 Values\", \"% of -999 Values\"])\n",
    "    for col in df.columns: \n",
    "        #checking if there is any -999 in the column\n",
    "\n",
    "        if df[col].isin([-999]).sum()>0: \n",
    "            \n",
    "            # if -999 value present, total number of -999 value in the column stores here\n",
    "            total_negative_999 = df[col].isin([-999]).sum() \n",
    "            new_row = {'Feature':col, 'Total -999 Values':total_negative_999, '% of -999 Values':round(total_negative_999*100/len(df),2)}\n",
    "            #append row to the dataframe\n",
    "            col_negative999_df = col_negative999_df.append(new_row, ignore_index=True)\n",
    "            \n",
    "    col_negative999_df = col_negative999_df.sort_values(\"% of -999 Values\", ascending=False)    \n",
    "    return col_negative999_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a518b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check column na for whole df\n",
    "col_negative999_df =check_col_negative999(df)\n",
    "col_negative999_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367f395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking column for -9999 values\n",
    "def check_col_negative9999(df):\n",
    "    \"\"\"\n",
    "    Check each column for -9999 values. Returns Feature, total -9999 values and % of -9999 values for each column\n",
    "    df[DataFrame]: dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    col_negative9999_df = pd.DataFrame(columns =[\"Feature\", \"Total -9999 Values\", \"% of -9999 Values\"])\n",
    "    for col in df.columns: \n",
    "        #checking if there is any -9999 in the column\n",
    "\n",
    "        if df[col].isin([-9999]).sum()>0: \n",
    "            \n",
    "            # if -9999 value present, total number of -9999 value in the column stores here\n",
    "            total_negative_9999 = df[col].isin([-9999]).sum() \n",
    "            new_row = {'Feature':col, 'Total -9999 Values':total_negative_9999, '% of -9999 Values':round(total_negative_9999*100/len(df),2)}\n",
    "            #append row to the dataframe\n",
    "            col_negative9999_df = col_negative9999_df.append(new_row, ignore_index=True)\n",
    "            \n",
    "    col_negative9999_df = col_negative9999_df.sort_values(\"% of -9999 Values\", ascending=False)    \n",
    "    return col_negative9999_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322384ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check column na for whole df\n",
    "col_negative9999_df =check_col_negative9999(df)\n",
    "col_negative9999_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7f6ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking column for -555 values\n",
    "def check_col_negative555(df):\n",
    "    \"\"\"\n",
    "    Check each column for -555 values. Returns Feature, total -555 values and % of -555 values for each column\n",
    "    df[DataFrame]: dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    col_negative555_df = pd.DataFrame(columns =[\"Feature\", \"Total -555 Values\", \"% of -555 Values\"])\n",
    "    for col in df.columns: \n",
    "        #checking if there is any -555 in the column\n",
    "\n",
    "        if df[col].isin([-555]).sum()>0: \n",
    "            \n",
    "            # if -555 value present, total number of -555 value in the column stores here\n",
    "            total_negative_555 = df[col].isin([-555]).sum() \n",
    "            new_row = {'Feature':col, 'Total -555 Values':total_negative_555, '% of -555 Values':round(total_negative_555*100/len(df),2)}\n",
    "            #append row to the dataframe\n",
    "            col_negative555_df = col_negative555_df.append(new_row, ignore_index=True)\n",
    "            \n",
    "    col_negative555_df = col_negative555_df.sort_values(\"% of -555 Values\", ascending=False)    \n",
    "    return col_negative555_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e56541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check column na for whole df\n",
    "col_negative555_df =check_col_negative555(df)\n",
    "col_negative555_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d5668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Negative value imputation - Negative 5555 imputation \n",
    "def Negative_value_impute(df,imptype):\n",
    "    \"\"\"\n",
    "    Impute Negative value (can choose negative value to impute)\n",
    "    df[DataFrame]:df\n",
    "    imptype[string]: \"mean\" to impute data with mean, \"median\" to impute data with median\n",
    "    \"\"\"\n",
    "    if imptype == \"mean\":        \n",
    "        df = df.replace(-5555,df.mean())\n",
    "    if imptype == \"median\":\n",
    "        df = df.replace(-5555,df.median())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaedf6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Negative_value_impute(df,imptype=\"median\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17decc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Negative value imputation - Negative 999 imputation \n",
    "def Negative_value_impute(df,imptype):\n",
    "    \"\"\"\n",
    "    Impute Negative value (can choose negative value to impute)\n",
    "    df[DataFrame]:df\n",
    "    imptype[string]: \"mean\" to impute data with mean, \"median\" to impute data with median\n",
    "    \"\"\"\n",
    "    if imptype == \"mean\":        \n",
    "        df = df.replace(-999,df.mean())\n",
    "    if imptype == \"median\":\n",
    "        df = df.replace(-999,df.median())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a6dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Negative_value_impute(df,imptype=\"median\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118206a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Negative value imputation - Negative 9999 imputation \n",
    "def Negative_value_impute(df,imptype):\n",
    "    \"\"\"\n",
    "    Impute Negative value (can choose negative value to impute)\n",
    "    df[DataFrame]:df\n",
    "    imptype[string]: \"mean\" to impute data with mean, \"median\" to impute data with median\n",
    "    \"\"\"\n",
    "    if imptype == \"mean\":        \n",
    "        df = df.replace(-9999,df.mean())\n",
    "    if imptype == \"median\":\n",
    "        df = df.replace(-9999,df.median())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be8f8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Negative_value_impute(df,imptype=\"median\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df369736",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Negative value imputation - Negative 555 imputation \n",
    "#Negative value imputation\n",
    "def Negative_value_impute(df,imptype):\n",
    "    \"\"\"\n",
    "    Impute Negative value (can choose negative value to impute)\n",
    "    df[DataFrame]:df\n",
    "    imptype[string]: \"mean\" to impute data with mean, \"median\" to impute data with median\n",
    "    \"\"\"\n",
    "    if imptype == \"mean\":        \n",
    "        df = df.replace(-555,df.mean())\n",
    "    if imptype == \"median\":\n",
    "        df = df.replace(-555,df.median())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3194093",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Negative_value_impute(df,imptype=\"median\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a6c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check if all negative values have been converted\n",
    "#Filter only numeric data\n",
    "df_numeric = df._get_numeric_data()\n",
    "df_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204e014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#False if no negative values found in columns \n",
    "pd.set_option(\"max_rows\", None)\n",
    "print([(df_numeric < 0).all(axis=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516a58d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter columns with negative values\n",
    "df_negative = df_numeric.loc[:,(df_numeric < 0).any()]\n",
    "df_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eb9767",
   "metadata": {},
   "source": [
    "### 4) Check and remove unary(single value) columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ae7609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unary(df):\n",
    "    \"\"\"\n",
    "    Checks for unary columns. If there are unary columns, the unary columns will be printed and removed from the df\n",
    "    df[DataFrame]: input dataframe\n",
    "    \"\"\"\n",
    "    unarycolumns = [col for col in df.columns if len(df[col].unique())==1]\n",
    "    if unarycolumns:\n",
    "        print(\"The unary column are:\",unarycolumns)\n",
    "        df = df.drop(unarycolumns,axis=1)\n",
    "        print(\"Unary columns dropped!\")\n",
    "        return df \n",
    "    else:\n",
    "        print(\"There are no unary columns!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47259533",
   "metadata": {},
   "outputs": [],
   "source": [
    "unary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650e4872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supporting_fs = ['SPECKLE','VID','ULT@MIDAS_6261_U1', 'SORTLOT', 'SORTLOT7', 'WAFER',\n",
    "#        'XLOC', 'YLOC', 'ULT@MIDAS_6261_U2', 'IB@6261[CLASSHOT]',\n",
    "#        'FB@6261[CLASSHOT]','ARR_SPECKLE_SCREEN::PHYTON_X_USERFUNC_K_END_X_X_X_X_PBISTSPECKLE_INDICATOR::DUTCPUBAD_1@6261[CLASSHOT]',\n",
    "#        'TEST RESULTS', 'TEST RESULTS BITS', 'TR_BITS', 'INCOMING',\n",
    "#        'INCOMING BITS', 'INC_BITS', 'OUTGOING', 'OUTGOING BITS', 'OUT_BITS','DELTA']\n",
    "# sf_df = df[supporting_fs]\n",
    "# df1 = df.drop(supporting_fs,axis=1) \n",
    "# df2 = df1.drop(['PTH_POWER::POWER_X_SCREEN_E_BEGIN_X_X_X_X_CALC_PP_CDYN_INDICATOR_CDYN_DATA@132110'],axis=1)\n",
    "# df_neg = df2.loc[:,((df2 == -555).any()) | ((df2 == -999).any())]\n",
    "# df_neg_sf = pd.concat([sf_df,df_neg],axis=1)\n",
    "# df_neg_sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8f3a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.columns.difference(df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3906fcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1['PTH_POWER::POWER_X_SCREEN_E_BEGIN_X_X_X_X_CALC_PP_CDYN_INDICATOR_CDYN_DATA@132110']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706d1a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df1.drop(['PTH_POWER::POWER_X_SCREEN_E_BEGIN_X_X_X_X_CALC_PP_CDYN_INDICATOR_CDYN_DATA@132110'],axis=1)\n",
    "# df_neg = df2.loc[:,((df2 == -555).any()) | ((df2 == -999).any())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce466636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_neg_sf = pd.concat([sf_df,df_neg],axis=1)\n",
    "# df_neg_sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0184a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_neg_sf.to_csv(path+\"/DataPreparation/Negative_Cols_555_999.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bb6884",
   "metadata": {},
   "source": [
    "### 5) Split data into train and validation datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e800b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "def randomsamp(df,val_size):\n",
    "    \"\"\"\n",
    "    Split whole dataset into train and validation using random sampling\n",
    "    Returns X_train, X_val, y_train, y_val\n",
    "    df[DataFrame]: input dataframe    \n",
    "    val_size[float]:Should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the val split. \n",
    "                    Train size is complement of val size\n",
    "    \"\"\"\n",
    "    X= df.drop([\"SPECKLE\"],axis=1)\n",
    "    y= df[\"SPECKLE\"] \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = val_size,random_state=42,stratify= df[\"SPECKLE\"])\n",
    "    if type(val_size)==float:\n",
    "        print(\"Train-val split completed with\",(1-val_size)*100,\"-\",val_size*100,\"split in train-val\")\n",
    "    print(\"Shape of X_train is:\", X_train.shape)\n",
    "    print(\"Shape of X_val is:\",X_val.shape)\n",
    "    print(\"Shape of y_train is:\",y_train.shape)\n",
    "    print(\"Shape of y_val is:\",y_val.shape)\n",
    "    print(\"Distribution of y_train:\",Counter(y_train))\n",
    "    print(\"Distribution of y_val:\",Counter(y_val))\n",
    "    \n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    X_val = X_val.reset_index(drop=True)\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    y_val = y_val.reset_index(drop=True)        \n",
    "           \n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "def targetrandomsamp(df,speckle_test_size,nonspeckle_test_size):\n",
    "    \"\"\"\n",
    "    Dataset is split into speckle/non-speckle first. The speckle/non-speckle datasets are then split \n",
    "    into train and validation using random sampling, followed by merging of the speckle/non-speckle  \n",
    "    to return X_train, X_val, y_train, y_val\n",
    "    \n",
    "    df[DataFrame]: input dataframe  \n",
    "    \n",
    "    speckle_test_size[float/int]: Val size for speckle \n",
    "    -If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the val split. \n",
    "    -If int, represents the absolute number of val samples.\n",
    "    -Train size is complement of val size\n",
    "    \n",
    "    nonspeckle_test_size[float/int]: Val size for non-speckle \n",
    "    -If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the val split. \n",
    "    -If int, represents the absolute number of val samples.\n",
    "    -Train size is complement of val size\n",
    "    \n",
    "    \"\"\"\n",
    "    #split data into speckle/nonspeckle\n",
    "    df_s = df.loc[df[\"SPECKLE\"] == 1] #speckle\n",
    "    df_ns = df.loc[df[\"SPECKLE\"] == 0] #nonspeckle\n",
    "    \n",
    "    #split speckle/nonspeckle data into train/validation\n",
    "    print(\"For speckle data:\")\n",
    "    X_train_s, X_val_s, y_train_s, y_val_s = randomsamp(df_s,val_size=speckle_test_size)\n",
    "    print(\"\\nFor non-speckle data:\")\n",
    "    X_train_ns, X_val_ns, y_train_ns, y_val_ns = randomsamp(df_ns,val_size=nonspeckle_test_size)\n",
    "    \n",
    "    #concat the speckle/non-speckle train and validation\n",
    "    X_train = pd.concat([X_train_s,X_train_ns], ignore_index=True)\n",
    "    X_val = pd.concat([X_val_s,X_val_ns], ignore_index=True)\n",
    "    y_train = pd.concat([y_train_s,y_train_ns], ignore_index=True)\n",
    "    y_val = pd.concat([y_val_s,y_val_ns], ignore_index=True)\n",
    "    \n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    X_val = X_val.reset_index(drop=True)\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    y_val = y_val.reset_index(drop=True)  \n",
    "    \n",
    "    print(\"\\nFinal dataset:\")\n",
    "    print(\"Distribution of y_train:\",Counter(y_train))\n",
    "    print(\"Distribution of y_val:\",Counter(y_val))\n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738c7fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SPECKLE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c630093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split on whole data\n",
    "X_train, X_val, y_train,y_val = randomsamp(df,val_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495abae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split on speckle/non-speckle then merge\n",
    "X_train, X_val, y_train, y_val = targetrandomsamp(df,speckle_test_size=500,nonspeckle_test_size=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f07015",
   "metadata": {},
   "source": [
    "### 6) Remove supporting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f33ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "supporting_fs = ['VID','ULT@MIDAS_6261_U1', 'SORTLOT', 'SORTLOT7', 'WAFER',\n",
    "       'XLOC', 'YLOC', 'ULT@MIDAS_6261_U2', 'IB@6261[CLASSHOT]',\n",
    "       'FB@6261[CLASSHOT]', 'TEST RESULTS', 'TEST RESULTS BITS', 'TR_BITS',\n",
    "       'INCOMING', 'INCOMING BITS', 'INC_BITS', 'OUTGOING', 'OUTGOING BITS',\n",
    "       'OUT_BITS', 'DELTA']\n",
    "X_train_sf = X_train[supporting_fs] #keep supporting fs of X_train\n",
    "X_val_sf = X_val[supporting_fs] #keep supporting fs of X_val\n",
    "X_train = X_train.drop(supporting_fs,axis=1) #remove supporting fs from X_train\n",
    "X_val = X_val.drop(supporting_fs,axis=1) #remove supporting fs from X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031fc51c",
   "metadata": {},
   "source": [
    "### 7) Scaling the data (Standardization/Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccbba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To scale X train and X validation (test) data using various scalers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def scale_data(X_train,X_val,scaler_type):\n",
    "    \"\"\"\n",
    "    Scaling X train and validation with standardization or normalization\n",
    "    params:\n",
    "    X_train[DataFrame]: input X train\n",
    "    X_val[DataFrame]: input X validation (test)\n",
    "    scaler_type[None/string]: input scaling method\n",
    "    - \"Standardization\" for Standard Scaler\n",
    "    - \"Normalization\" for Min Max Scaler    \n",
    "\n",
    "    \"\"\"           \n",
    "    if scaler_type == \"Standardization\":\n",
    "        scaler = StandardScaler()\n",
    "    if scaler_type == \"Normalization\":\n",
    "        scaler = MinMaxScaler()\n",
    "\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled,columns= X_train.columns)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_val_scaled = pd.DataFrame(X_val_scaled,columns= X_val.columns)\n",
    "       \n",
    "    return X_train_scaled, X_val_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c61e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X train-test scaled using Min max Scaler\n",
    "X_train_scaled, X_val_scaled = scale_data(X_train,X_val,scaler_type = \"Normalization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa5066c",
   "metadata": {},
   "source": [
    "### 8) Handling highly correlated features (features vs features/features vs target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b96d23",
   "metadata": {},
   "source": [
    "#### a) features vs features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c016c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "start = time.time()\n",
    "\n",
    "#To create correlation matrix for X_train (features)\n",
    "correlation_matrix = X_train_scaled.corr().abs()\n",
    "\n",
    "#To select the upper trigular matrix from the correlation matrix of features\n",
    "upper_tri = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape),k=1).astype(np.bool))\n",
    "display(upper_tri)\n",
    "\n",
    "highly_corr_features_95 = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\n",
    "\n",
    "end = time.time()\n",
    "print (\"Time elapsed:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744ab3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(highly_corr_features_95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247cbc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display correlation matrix pairs (sorted in descending order)\n",
    "correlation_matrix_stack = X_train_scaled.corr().abs()\n",
    "\n",
    "#the matrix is symmetric so we need to extract upper triangle matrix without diagonal (k = 1)\n",
    "\n",
    "upper_tri_stack = (correlation_matrix_stack.where(np.triu(np.ones(correlation_matrix_stack.shape), k=1).astype(np.bool))\n",
    "                  .stack()\n",
    "                  .sort_values(ascending=False))\n",
    "\n",
    "#first element of upper_tri_stack series is the pair with the biggest correlation\n",
    "display(upper_tri_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b14ed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "highly_corr_features_df = pd.DataFrame (highly_corr_features_95, columns = ['Feature'])\n",
    "highly_corr_features_df.to_csv(path+\"/DataPreparation/highly_corr_features_95.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f3bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the columns with high correlation\n",
    "X_train_scaled = X_train_scaled.drop(highly_corr_features_95, axis=1)\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082c4dc2",
   "metadata": {},
   "source": [
    "#### b) features vs target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daddeea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create correlation matrix for X_train (features) and y_train (target)\n",
    "correlation_matrix_target = X_train_scaled.corrwith(y_train, axis = 0).abs()\n",
    "display(correlation_matrix_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa6f932",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix_target_df = pd.DataFrame(correlation_matrix_target)\n",
    "correlation_matrix_target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5816d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding column name to the respective columns\n",
    "correlation_matrix_target_df.columns =['Variables']\n",
    "display(correlation_matrix_target_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447154a0",
   "metadata": {},
   "source": [
    "### B) Sampling to address class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8146de",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62848b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "\n",
    "#SMOTE\n",
    "def SMOTE_sampling(X_train_scaled,y_train,over_amt,under_amt=None):\n",
    "    \"\"\"\n",
    "    Can choose SMOTE or SMOTE + random undersampling\n",
    "    X_train_scaled[DataFrame]: X_train after scaling\n",
    "    y_train[DataFrame] : target in train data\n",
    "    over_amt [int] : amount of synthetic data to be generated with SMOTE (speckle)\n",
    "    under_amt[int/None]: int - amount of nonspeckle data after undersampling\n",
    "                         None - No undersampling is done\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"Class distribution before sampling:\", Counter(y_train))\n",
    "    print(\"Ratio of class distribution before sampling :\",round(Counter(y_train)[0]/Counter(y_train)[1],2))\n",
    "    \n",
    "    if under_amt == None: #SMOTE only\n",
    "        sm = SMOTE(sampling_strategy= {1:over_amt},random_state=42)\n",
    "        X_s, y_s = sm.fit_resample(X_train_scaled, y_train)\n",
    "        \n",
    "    else: #SMOTE + random undersampling\n",
    "        sm = SMOTE(sampling_strategy={1:over_amt},random_state=42)\n",
    "        under = RandomUnderSampler(sampling_strategy={0:under_amt},random_state=42)\n",
    "        pipeline = Pipeline(steps=[('o', sm), ('u', under)])\n",
    "        X_s, y_s = pipeline.fit_resample(X_train_scaled, y_train)    \n",
    "         \n",
    "    print(\"Class distribution after sampling:\", Counter(y_s))     \n",
    "    print(\"Ratio of class distribution after sampling :\",round(Counter(y_s)[0]/Counter(y_s)[1],2)) \n",
    "    \n",
    "    return X_s, y_s\n",
    "\n",
    "#BorderlineSMOTE\n",
    "def BorderlineSMOTE_sampling(X_train_scaled,y_train,over_amt,under_amt=None):\n",
    "    \"\"\"\n",
    "    Can choose BorderlineSMOTE or BorderlineSMOTE + random undersampling\n",
    "    X_train_scaled[DataFrame]: X_train after scaling\n",
    "    y_train[DataFrame] : target in train data\n",
    "    supporting_fs[list] : list of supporting features to be removed from X_train_scaled\n",
    "    over_amt [int] : amount of synthetic data to be generated with BorderlineSMOTE\n",
    "    under_amt[int/None]: int - amount of nonspeckle data after undersampling\n",
    "                         None - No undersampling is done\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"Class distribution before sampling:\", Counter(y_train))\n",
    "    print(\"Ratio of class distribution before sampling :\",round(Counter(y_train)[0]/Counter(y_train)[1],2))\n",
    "    \n",
    "    if under_amt == None: #BorderlineSMOTE only\n",
    "        bsm = BorderlineSMOTE(sampling_strategy= {1:over_amt},random_state=42)\n",
    "        X_bs, y_bs = bsm.fit_resample(X_train_scaled, y_train)\n",
    "        \n",
    "    else: #BorderlineSMOTE + random undersampling\n",
    "        bsm = BorderlineSMOTE(sampling_strategy={1:over_amt},random_state=42)\n",
    "        under = RandomUnderSampler(sampling_strategy={0:under_amt},random_state=42)\n",
    "        pipeline = Pipeline(steps=[('o', bsm), ('u', under)])\n",
    "        X_bs, y_bs = pipeline.fit_resample(X_train_scaled, y_train)    \n",
    "         \n",
    "    print(\"Class distribution after sampling:\", Counter(y_bs))     \n",
    "    print(\"Ratio of class distribution after sampling :\",round(Counter(y_bs)[0]/Counter(y_bs)[1],2)) \n",
    "    \n",
    "    return X_bs, y_bs\n",
    "\n",
    "#ADASYN\n",
    "def ADASYN_sampling(X_train_scaled,y_train,over_amt,under_amt=None):\n",
    "    \"\"\"\n",
    "    Can choose ADASYN or ADASYN + random undersampling\n",
    "    X_train_scaled[DataFrame]: X_train after scaling\n",
    "    y_train[DataFrame] : target in train data\n",
    "    supporting_fs[list] : list of supporting features to be removed from X_train_scaled\n",
    "    over_amt [int] : amount of synthetic data to be generated with ADASYN\n",
    "    under_amt[int/None]: int - amount of nonspeckle data after undersampling\n",
    "                         None - No undersampling is done\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"Class distribution before sampling:\", Counter(y_train))\n",
    "    print(\"Ratio of class distribution before sampling :\",round(Counter(y_train)[0]/Counter(y_train)[1],2))\n",
    "    \n",
    "    if under_amt == None: #ADASYN only\n",
    "        ad = ADASYN(sampling_strategy= {1:over_amt},random_state=42)\n",
    "        X_a, y_a = ad.fit_resample(X_train_scaled, y_train)\n",
    "        \n",
    "    else: #ADASYN + random undersampling\n",
    "        ad = ADASYN(sampling_strategy={1:over_amt},random_state=42)\n",
    "        under = RandomUnderSampler(sampling_strategy={0:under_amt},random_state=42)\n",
    "        pipeline = Pipeline(steps=[('o', ad), ('u', under)])\n",
    "        X_a, y_a = pipeline.fit_resample(X_train_scaled, y_train)    \n",
    "         \n",
    "    print(\"Class distribution after sampling:\", Counter(y_a))     \n",
    "    print(\"Ratio of class distribution after sampling :\",round(Counter(y_a)[0]/Counter(y_a)[1],2)) \n",
    "    \n",
    "    return X_a, y_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb21b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE\n",
    "X_s, y_s = SMOTE_sampling(X_train_scaled,y_train,over_amt=2000,under_amt=2000)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054b46c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BorderlineSMOTE\n",
    "X_bs, y_bs = BorderlineSMOTE_sampling(X_train_scaled,y_train,over_amt=2000,under_amt=2000)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035f6137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADASYN\n",
    "X_a, y_a = ADASYN_sampling(X_train_scaled,y_train,over_amt=2000,under_amt=None)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac431442",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column for target\n",
    "# import numpy as np\n",
    "# df[\"SPECKLE\"] = np.where(df[\"DELTA\"]==0,0,1)\n",
    "# cols = df.columns.tolist()\n",
    "# cols = [cols[-1]]+cols[:-1] #move speckle col to the front\n",
    "# df = df.reindex(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532dc991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(path+\"SNR_R2_ww35.2_Speckle.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d02e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supporting_fs = ['ULT@MIDAS_6261_U1', 'SORTLOT', 'SORTLOT7', 'WAFER',\n",
    "#        'XLOC', 'YLOC', 'ULT@MIDAS_6261_U2', 'IB@6261[CLASSHOT]',\n",
    "#        'FB@6261[CLASSHOT]','ARR_SPECKLE_SCREEN::PHYTON_X_USERFUNC_K_END_X_X_X_X_PBISTSPECKLE_INDICATOR::DUTCPUBAD_1@6261[CLASSHOT]',\n",
    "#        'TEST RESULTS', 'TEST RESULTS BITS', 'TR_BITS', 'INCOMING',\n",
    "#        'INCOMING BITS', 'INC_BITS', 'OUTGOING', 'OUTGOING BITS', 'OUT_BITS','DELTA']\n",
    "# df1 = df.drop(supporting_fs,axis=1) \n",
    "# df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fd7a11",
   "metadata": {},
   "source": [
    "### 3) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f65f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make folder for featureselection if it doesn't exist\n",
    "import os\n",
    "featuresel_path = path + 'FeatureSelection/' \n",
    "if not os.path.exists(featuresel_path):\n",
    "    os.makedirs(featuresel_path)\n",
    "    print(\"FeatureSelection folder created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c36d2a",
   "metadata": {},
   "source": [
    "#### a) ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06db15d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def anova_fs(X_train_scaled,y_train):\n",
    "    \"\"\"\n",
    "    Anova feature selection. Return the top k features \n",
    "    X_train_scaled[df]: X of train data\n",
    "    y_train[df]: y of train data (target)\n",
    "    num_top_fs[int/\"all\"]: int -> specify the number of top fs to be returned,\n",
    "                                  returns top fs and their scores in descending order\n",
    "                           \"all\" -> returns all fs and their scores in descending order\n",
    "    \"\"\"\n",
    "    #Select k features with top Fisher scores\n",
    "    anova = SelectKBest(f_classif, k = \"all\")    \n",
    "    anova.fit(X_train_scaled, y_train)\n",
    "            \n",
    "    #get the top feature names\n",
    "    fs_names = X_train_scaled.columns.values[anova.get_support()] \n",
    "\n",
    "    #get the top feature scores\n",
    "    scores = anova.scores_[anova.get_support()] \n",
    "    \n",
    "    #dataframe with feature name and score in descending order\n",
    "    names_scores = list(zip(fs_names, scores))\n",
    "    ns_df = pd.DataFrame(data = names_scores, columns=['Feature', 'Scores'])\n",
    "    ns_df = ns_df.sort_values(by=['Scores'], ascending=False)    \n",
    "    ns_df['Scores_Scaled'] = ns_df['Scores']/ns_df['Scores'].sum()\n",
    "    ns_df['Scores_Scaled_Cumulative %'] = ns_df['Scores_Scaled'].cumsum()*100\n",
    "    ns_df = ns_df.reset_index(drop=True)\n",
    "    \n",
    "    return anova, ns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c19c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "anova,ns_df = anova_fs(X_train_scaled,y_train)\n",
    "print(anova)\n",
    "ns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2f9c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_df.to_csv(featuresel_path+\"Anova_Fs.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1645178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take top n important features only in train and validation\n",
    "n=200\n",
    "features = ns_df.head(n)[[\"Feature\"]] #choose the top n important features\n",
    "X_train_scaled = X_train_scaled[features[\"Feature\"]] #filter X_train_scaled with top n important features\n",
    "X_val_scaled = X_val_scaled[features[\"Feature\"]] #filter X_val_scaled with top n important features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ac5ae2",
   "metadata": {},
   "source": [
    "### b) Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132325bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a376bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccde21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Build the grid search on random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "param_grid = {\n",
    "#     'n_estimators': [100, 300], # number of trees, default is 100 -> not used as Boruta will determine\n",
    "    'max_depth': [3,5,7], #max_depth of the tree is advised on the Boruta Github page to be between 3 to 7\n",
    "    'max_features': ['auto','log2'], #number of features to consider when looking for the best split, default auto\n",
    "    'min_samples_leaf': [1,100], # minimum sample leaf (decision tree end node) size, default is 1\n",
    "    'class_weight': [None,'balanced'], #weights for unbalanced data     \n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier() \n",
    "grid = GridSearchCV(estimator=rf_model, param_grid=param_grid,scoring='balanced_accuracy',n_jobs = -1,verbose=2,cv = 5)\n",
    "grid_results = grid.fit(X_train_scaled,y_train) \n",
    "\n",
    "print(\"Best parameters:\", grid_results.best_params_)\n",
    "\n",
    "#model with best parameters\n",
    "model = grid_results.best_estimator_ \n",
    "print(model)\n",
    "\n",
    "fs_importance= pd.DataFrame(list(zip(X_train_scaled.columns, model.feature_importances_)), columns=['Feature', 'Importance']).sort_values(by=['Importance'], ascending=False)  \n",
    "display(fs_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a61de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(grid_results.cv_results_)\n",
    "results_df= results_df.drop([\"mean_fit_time\",\"std_fit_time\",\"mean_score_time\",\"std_score_time\",\"split0_test_score\",\"split1_test_score\",\"split2_test_score\",\"split3_test_score\",\"split4_test_score\"],axis=1)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e178c72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_fs_importance.to_csv(featuresel_path+\"RandomForest.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e684be18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_fs_importance[\"Importance\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65885b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Creating a BorutaPy object with RandomForestClassifier as the estimator and ranking the features\n",
    "from boruta import BorutaPy\n",
    "boruta_selector = BorutaPy(best_rf_model, n_estimators='auto', verbose=2, perc = 90,max_iter = 100, random_state=42)                                                      \n",
    "boruta_selector.fit(np.array(X_train_scaled), np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01db1bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boruta_selector)\n",
    "print(\"No. of significant features: \", boruta_selector.n_features_) \n",
    "selected_boruta_fs = pd.DataFrame({'Feature':list(X_train_scaled.columns),'Ranking':boruta_selector.ranking_}).sort_values(by='Ranking')\n",
    "selected_boruta_fs = selected_boruta_fs[selected_boruta_fs['Ranking']==1]\n",
    "selected_boruta_fs = selected_boruta_fs[[\"Feature\"]]\n",
    "selected_boruta_fs_imp = rf_fs_importance.loc[rf_fs_importance['Feature'].isin(selected_boruta_fs['Feature']),:]\n",
    "selected_boruta_fs_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ab81d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_boruta_fs_imp.to_csv(featuresel_path+\"Boruta.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028302ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take important features only in train and validation\n",
    "X_train_scaled = X_train_scaled[selected_boruta_fs_imp[\"Feature\"]]\n",
    "X_val_scaled = X_val_scaled[selected_boruta_fs_imp[\"Feature\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4525505",
   "metadata": {},
   "source": [
    "### c) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c635c3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5a7eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27d6a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the grid search\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300], # number of trees, default is 100\n",
    "    'max_features': ['auto','log2'], #number of features to consider when looking for the best split, default auto\n",
    "    'min_samples_leaf': [1,100], # minimum sample leaf (decision tree end node) size, default is 1\n",
    "    'class_weight': [None,'balanced'], #weights for unbalanced data     \n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "# Grid search on random forest\n",
    "rf_model = RandomForestClassifier() \n",
    "grid = GridSearchCV(estimator=rf_model, param_grid=param_grid,scoring='balanced_accuracy',n_jobs = -1,verbose=2,cv = 5)\n",
    "grid_results = grid.fit(X_train_scaled,y_train) \n",
    "\n",
    "\n",
    "# # Print the time spend and number of models ran\n",
    "# print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\" % ((time.time() - start), len(grid_results.cv_results_['params'])))\n",
    "\n",
    "end = time.time()\n",
    "print (\"Time elapsed:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba458210",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters:\", grid_results.best_params_)\n",
    "#model with best parameters\n",
    "best_rf_model = grid_results.best_estimator_ \n",
    "best_rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0643ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_fs_importance= pd.DataFrame(list(zip(X_train_scaled.columns, best_rf_model.feature_importances_)), columns=['Feature', 'Importance']).sort_values(by=['Importance'], ascending=False)  \n",
    "rf_fs_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0129d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(grid_results.cv_results_)\n",
    "results_df= results_df.drop([\"mean_fit_time\",\"std_fit_time\",\"mean_score_time\",\"std_score_time\",\"split0_test_score\",\"split1_test_score\",\"split2_test_score\",\"split3_test_score\",\"split4_test_score\"],axis=1)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421462ad",
   "metadata": {},
   "source": [
    "### d) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604431f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the grid search\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 600],\n",
    "    'learning_rate': [0.01],\n",
    "    'min_child_weight': [2, 7],\n",
    "    'gamma': [0.5, 4],\n",
    "    'subsample': [0.5, 1.0],\n",
    "    'colsample_bytree': [0.5, 1.0],\n",
    "    'max_depth': [3, 5],\n",
    "    'objective': ['binary:logistic'],\n",
    "    'nthread': [1],\n",
    "    'verbosity': [0],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "# Grid search on XGBoost\n",
    "xgb_model = XGBClassifier()\n",
    "grid = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv = 5)\n",
    "grid_results = grid.fit(X_train_scaled,y_train) \n",
    "\n",
    "# # Print the time spend and number of models ran\n",
    "# print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\" % ((time.time() - start), len(grid_results.cv_results_['params'])))\n",
    "\n",
    "end = time.time()\n",
    "print (\"Time elapsed:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4faa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters:\", grid_results.best_params_)\n",
    "#model with best parameters\n",
    "best_xgb_model = grid_results.best_estimator_ \n",
    "best_xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b79a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_fs_importance = pd.DataFrame(list(zip(X_train_scaled.columns, best_xgb_model.feature_importances_)), columns=['Feature', 'Importance']).sort_values(by=['Importance'], ascending=False)  \n",
    "xgb_fs_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4d2b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(grid_results.cv_results_)\n",
    "results_df= results_df.drop([\"mean_fit_time\",\"std_fit_time\",\"mean_score_time\",\"std_score_time\",\"split0_test_score\",\"split1_test_score\",\"split2_test_score\",\"split3_test_score\",\"split4_test_score\"],axis=1)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4056006a",
   "metadata": {},
   "source": [
    "### f) Ensemble feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ada714",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c987ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7efbc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "anova._estimator_type = \"classifier\"\n",
    "from xgboost import XGBClassifier\n",
    "best_xgb_model = XGBClassifier(random_state = 42)\n",
    "\n",
    "#ensemble feature selection\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "#specify the estimators to use, specify anova first if it is used\n",
    "estimators = [('ANOVA',anova),('XGB',best_xgb_model),('RF', best_rf_model)] \n",
    "voting_clf = VotingClassifier(estimators=estimators, voting='soft', weights=[1,1,1])\n",
    "voting_clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_feature_importance(voting_clf, weights):\n",
    "    \"\"\" \n",
    "    Function to compute feature importance of ensemble feature selection \n",
    "    voting_clf = Voting Classifier object\n",
    "    weights = weights used for each estimator \n",
    "    \"\"\"\n",
    "    \n",
    "    feature_importance = dict()\n",
    "    anova_featureimp = dict()\n",
    "\n",
    "    try: # anova is not one of the estimators\n",
    "        for est in voting_clf.estimators_:\n",
    "            feature_importance[str(est)] = est.feature_importances_ #get the feature imp for each estimator\n",
    "    except: #if anova is one of the estimators\n",
    "        #get the feature imp for anova\n",
    "        anova_featureimp[voting_clf.estimators_[0]] = voting_clf.estimators_[0].scores_/voting_clf.estimators_[0].scores_.sum()\n",
    "        #get the feature imp for other estimators\n",
    "        for est in voting_clf.estimators_[1:]: \n",
    "            feature_importance[str(est)] = est.feature_importances_ #get the feature imp for each estimator    \n",
    "        #combine feature imp of anova and other estimators\n",
    "        feature_importance.update(anova_featureimp)\n",
    "    \n",
    "    fe_scores = [0]*len(list(feature_importance.values())[0]) #initialize fe_scores as 0 \n",
    "    for idx, imp_score in enumerate(feature_importance.values()): #idx:estimator index, imp_score: feature imp of est\n",
    "        imp_score_with_weight = imp_score*weights[idx] #Multiply the weights of the base estimator to the importance score of each of the features.\n",
    "        fe_scores = list(np.add(fe_scores, list(imp_score_with_weight)))\n",
    "        \n",
    "    return fe_scores\n",
    "\n",
    "ensemble_fs = pd.DataFrame()\n",
    "ensemble_fs['Feature'] = X_train_scaled.columns\n",
    "ensemble_fs['Feature Importance'] = compute_feature_importance(voting_clf,weights = [1, 1, 1])\n",
    "ensemble_fs = ensemble_fs.sort_values('Feature Importance', ascending=False)\n",
    "ensemble_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc95998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take top n important features only in train and validation\n",
    "n=200\n",
    "features = ns_df.head(n)[[\"Feature\"]] #choose the top n important features\n",
    "X_train_scaled = X_train_scaled[features[\"Feature\"]] #filter X_train_scaled with top n important features\n",
    "X_val_scaled = X_val_scaled[features[\"Feature\"]] #filter X_val_scaled with top n important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bda0c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_fs.to_csv(featuresel_path+\"Ensemble_Anova_XGB_RF.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b138b357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f29af97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97ebab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede81ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dee7fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff4360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.read_csv(path+'DataPreparation/negative_parameters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1045388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8772af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_IDV = df2.loc[:, df2.columns.str.startswith(\"IDV\")]\n",
    "# df_IDV.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9162ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_IDV = df2.loc[:, df2.columns.str.startswith(\"IDV\")]\n",
    "# df_HVQK = df2.loc[:, df2.columns.str.startswith(\"HVQK\")]\n",
    "# df_IDV.min()\n",
    "# df_HVQK.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f030110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_HVQK = df2.loc[:, df2.columns.str.startswith(\"HVQK\")]\n",
    "# df_HVQK.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b271b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_IDV.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72d5eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_HVQK.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c7bf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.loc[:,((df2 == -5555).any()) & ((df2 == -9999).any())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cad9458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# path = \"C:/Users/nchong/OneDrive - Intel Corporation/Documents/ML based speckle POC/\"\n",
    "# df2 = pd.read_csv(path+\"SNR_R5_ww51.4.csv\")\n",
    "# df3 = df2[df2[\"VID\"].isin(row100na_df[\"VID\"])]\n",
    "# df3 = df3.reset_index(drop=True)\n",
    "# df3.shape\n",
    "# df3.to_csv(path+\"/DataPreparation/NA_rows_withsf.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb85a8f",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c170441",
   "metadata": {},
   "source": [
    "### a) SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a283a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C':[0.1, 1, 10, 100, 1000], #Regularization parameter [0.1, 1, 10, 100, 1000]\n",
    "    'kernel':['linear', 'poly', 'rbf', 'sigmoid'], #Specifies the kernel type to be used in the algorithm\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'class_weight': [None,'balanced'], #weights for unbalanced data     \n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "# Grid search on SVM\n",
    "classifier = SVC()\n",
    "grid = GridSearchCV(estimator=classifier, param_grid=param_grid,scoring='balanced_accuracy',refit = True,n_jobs = -1,verbose=2,cv = 5)\n",
    "grid_results = grid.fit(X_train_scaled,y_train) \n",
    "\n",
    "print(\"Best parameters:\", grid_results.best_params_)\n",
    "\n",
    "#model with best parameters\n",
    "model = grid_results.best_estimator_ \n",
    "print(model)\n",
    "\n",
    "# fs_importance= pd.DataFrame(list(zip(X_train_scaled.columns, model.feature_importances_)), columns=['Feature', 'Importance']).sort_values(by=['Importance'], ascending=False)  \n",
    "# display(fs_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ac67c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "grid_results= load(model_path+'SVMmodel.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b2130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check grid search results\n",
    "results_df = pd.DataFrame(grid_results.cv_results_)\n",
    "results_df= results_df.drop([\"mean_fit_time\",\"std_fit_time\",\"mean_score_time\",\"std_score_time\",\"split0_test_score\",\"split1_test_score\",\"split2_test_score\",\"split3_test_score\",\"split4_test_score\"],axis=1)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb7db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn import metrics\n",
    "\n",
    "#make folder for SVM if it doesn't exist\n",
    "import os\n",
    "model_path = path + 'ModelBuilding/SVM/' \n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "#MODEL SAVING   \n",
    "joblib.dump(model, model_path+\"SVMmodel.joblib\")\n",
    "\n",
    "# Predicting the classes for validation set\n",
    "y_pred = model.predict(X_val_scaled)\n",
    "\n",
    "#overall accuracy\n",
    "overall_acc = round(metrics.accuracy_score(y_val, y_pred)*100,2)\n",
    "overall_acc = {'Overall Acc %':overall_acc}\n",
    "overall_acc = pd.DataFrame([overall_acc])\n",
    "overall_acc.to_csv(model_path+\"Overall_Accuracy.csv\")\n",
    "\n",
    "#classification report\n",
    "report = metrics.classification_report(y_val, y_pred,zero_division=0,output_dict=True)\n",
    "report = pd.DataFrame(report).transpose()\n",
    "report.to_csv(model_path+\"Classification_Report.csv\")\n",
    "\n",
    "#confusion matrix with accuracies for each label\n",
    "class_accuracies = []\n",
    "\n",
    "for class_ in y_val.sort_values(ascending= True).unique():\n",
    "    class_acc = round(np.mean(y_pred[y_val == class_] == class_)*100,2)\n",
    "    class_accuracies.append(class_acc)\n",
    "    \n",
    "class_acc = pd.DataFrame(class_accuracies,index=['true:0', 'true:1'],columns= [\"Accuracy %\"])\n",
    "\n",
    "cf_matrix = pd.DataFrame(\n",
    "    metrics.confusion_matrix(y_val, y_pred, labels= [0, 1]), \n",
    "    index=['true:0', 'true:1'], \n",
    "    columns=['pred:0', 'pred:1']\n",
    ")\n",
    "\n",
    "ascend = None #input None/True/False to order the confusion matrix\n",
    "if ascend == None:\n",
    "    cf_matrix = pd.concat([cf_matrix,class_acc],axis=1)\n",
    "else:\n",
    "    cf_matrix = pd.concat([cf_matrix,class_acc],axis=1).sort_values(by=['Accuracy %'], ascending=ascend)\n",
    "\n",
    "cf_matrix.to_csv(model_path+\"Confusion_Matrix.csv\",index=False)   \n",
    "\n",
    "#validation results \n",
    "val_results = pd.concat([X_val_sf,X_val_scaled,pd.DataFrame(y_val),pd.DataFrame(y_pred,columns = [\"PRED_SPECKLE\"])],axis=1)\n",
    "val_results.to_csv(model_path+\"Val_results.csv\",index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae8de0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525bf233",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cf_matrix)\n",
    "display(overall_acc)\n",
    "display(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e68e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def plot_confusion_matrix(cm,\n",
    "#                           target_names,\n",
    "#                           title='Confusion matrix',\n",
    "#                           cmap=None,\n",
    "#                           normalize=True):\n",
    "#     \"\"\"\n",
    "#     given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "#     Arguments\n",
    "#     ---------\n",
    "#     cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "#     target_names: given classification classes such as [0, 1, 2]\n",
    "#                   the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "#     title:        the text to display at the top of the matrix\n",
    "\n",
    "#     cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "#                   see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "#                   plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "#     normalize:    If False, plot the raw numbers\n",
    "#                   If True, plot the proportions\n",
    "\n",
    "#     Usage\n",
    "#     -----\n",
    "#     plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "#                                                               # sklearn.metrics.confusion_matrix\n",
    "#                           normalize    = True,                # show proportions\n",
    "#                           target_names = y_labels_vals,       # list of names of the classes\n",
    "#                           title        = best_estimator_name) # title of graph\n",
    "\n",
    "#     Citiation\n",
    "#     ---------\n",
    "#     http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "#     \"\"\"\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     import numpy as np\n",
    "#     import itertools\n",
    "\n",
    "#     accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
    "#     misclass = 1 - accuracy\n",
    "\n",
    "#     if cmap is None:\n",
    "#         cmap = plt.get_cmap('Blues')\n",
    "\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar()\n",
    "\n",
    "#     if target_names is not None:\n",
    "#         tick_marks = np.arange(len(target_names))\n",
    "#         plt.xticks(tick_marks, target_names, rotation=45)\n",
    "#         plt.yticks(tick_marks, target_names)\n",
    "\n",
    "#     if normalize:\n",
    "#         cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "#     thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "#     for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "#         if normalize:\n",
    "#             plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "#                      horizontalalignment=\"center\",\n",
    "#                      color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "#         else:\n",
    "#             plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "#                      horizontalalignment=\"center\",\n",
    "#                      color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.ylabel('Actual')\n",
    "#     plt.xlabel('Predicted \\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb62fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = metrics.confusion_matrix(y_val, y_pred)\n",
    "# plot_confusion_matrix(cm=cm,target_names=[0,1],title='Confusion matrix', cmap=None,normalize=True)\n",
    "                          "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
